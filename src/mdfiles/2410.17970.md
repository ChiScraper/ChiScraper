---
abstract: Generative models cover various application areas, including image, video
  and music synthesis, natural language processing, and molecular design, among many
  others. As digital generative models become larger, scalable inference in a fast
  and energy-efficient manner becomes a challenge. Here, we present optical generative
  models inspired by diffusion models, where a shallow and fast digital encoder first
  maps random noise into phase patterns that serve as optical generative seeds for
  a desired data distribution; a jointly-trained free-space-based reconfigurable decoder
  all-optically processes these generative seeds to create novel images (never seen
  before) following the target data distribution. Except for the illumination power
  and the random seed generation through a shallow encoder, these optical generative
  models do not consume computing power during the synthesis of novel images. We report
  the optical generation of monochrome and multi-color novel images of handwritten
  digits, fashion products, butterflies, and human faces, following the data distributions
  of MNIST, Fashion MNIST, Butterflies-100, and Celeb-A datasets, respectively, achieving
  an overall performance comparable to digital neural network-based generative models.
  To experimentally demonstrate optical generative models, we used visible light to
  generate, in a snapshot, novel images of handwritten digits and fashion products.
  These optical generative models might pave the way for energy-efficient, scalable
  and rapid inference tasks, further exploiting the potentials of optics and photonics
  for artificial intelligence-generated content.
ai_rating: 2.5
ai_reason: "While the paper introduces innovative concepts in optical generative models\
  \ applicable to image synthesis, it does not align well with your specific research\
  \ interests in Free Space Optical Communication technologies, particularly adaptive\
  \ optics and wavefront sensing. Your focus on \"fiber optic technology for wavefront\
  \ sensing\" contrasts sharply with the abstract\u2019s emphasis on \"optical generative\
  \ models\" in various unrelated application areas, thus providing little direct\
  \ value to your work."
arxiv_id: '2410.17970'
authors:
- Shiqi Chen
- Yuhang Li
- Hanlong Chen
- Aydogan Ozcan
category_others:
- cs.LG
- physics.app-ph
- physics.optics
category_primary: cs.NE
config_reason_FSOC:
- false
- true
- false
config_tags:
- '#FSOC'
date_published: '2024-10-23'
date_updated: '2024-10-23'
title: Optical Generative Models
url_pdf: http://arxiv.org/pdf/2410.17970v1
---
 - [u] #task status
